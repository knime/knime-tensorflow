<?xml version="1.0" encoding="UTF-8"?>
<knimeNode icon="dlexecutor.png" type="Predictor"
	xmlns="http://knime.org/node/v3.6"
	xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
	xsi:schemaLocation="http://knime.org/node/v3.6 http://knime.org/node/v3.6.xsd">
	<name>TensorFlow 1 Network Executor</name>

	<shortDescription>
		Executes a TensorFlow deep learning network.
	</shortDescription>

	<fullDescription>
		<intro>
			This node executes a TensorFlow deep learning network on a
			compatible external back end that can be selected by the user.
		</intro>
		<tab name="General Settings">
			<option name="Back end">
				The deep learning back end which is used to
				execute the input network for the given input data.
			</option>
			<option name="Input batch size">
				The number of rows that are processed at a time.
			</option>
		</tab>
		<tab name="Inputs">
			<option name="Conversion">
				The converter that is used to transform the
				selected input columns into a format that is accepted by the
				respective network input specification.
			</option>
			<option name="Input columns">
				The table columns that are part of the respective
				network input.
				The availability of a column depends on the currently
				selected input converter.
			</option>
		</tab>
		<tab name="Outputs">
			<option name="Conversion">
				The converter that is used to transform the
				network output into table columns.
			</option>
			<option name="Output columns prefix">
				The prefix that is used to distinguish between
				the columns of the different outputs.
			</option>
		</tab>
		<tab name="GPU Configuration">
			<option name="Visible devices list">
				A comma-separated list of GPU ids that determines the 'visible' to
				'virtual' mapping of GPU devices. For example, if TensorFlow can see
				8 GPU devices in the process, and one wanted to map visible GPU
				devices 5 and 3 as "/device:GPU:0", and "/device:GPU:1", then one
				would specify this field as "5,3". This field is similar in spirit
				to the CUDA_VISIBLE_DEVICES environment variable, except it applies
				to the visible GPU devices in the process and must list only valid
				GPU indices.
				<br></br>
				<br></br>
				NOTE:
				<br></br>
				The GPU driver provides the process with the visible GPUs in an
				order which is not guaranteed to have any correlation to the
				*physical* GPU id in the machine. This field is used for remapping
				"visible" to "virtual", which means this operates only after the
				process starts. You should set the environment variable
				CUDA_VISIBLE_DEVICES prior to starting KNIME to ensure the device
				visibility and order (See
				<a
					href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#env-vars">CUDA Environment Variables</a>
				).
			</option>
			<option name="Per process GPU memory fraction">
				Fraction of the available GPU memory to allocate
				for each process. 1 means to allocate all of the GPU memory, 0.5
				means the process allocates up to ~50% of the available GPU memory.
			</option>
		</tab>
		<link href="https://www.knime.com/deeplearning/tensorflow">
			KNIME Deep Learning TensorFlow Integration
		</link>
	</fullDescription>

	<ports>
		<inPort index="0" name="TensorFlow Network">The TensorFlow deep learning network.
		</inPort>
		<inPort index="1" name="Data Table">The input table.</inPort>
		<outPort index="0" name="Data Table">The output table.</outPort>
	</ports>
</knimeNode>
